= Air-Gapped Environment

This section describes how to use SUSE® Virtualization in an air gapped environment. Some use cases could be where SUSE® Virtualization will be installed offline, behind a firewall, or behind a proxy.

The ISO image contains all the packages to make it work in an air gapped environment.

== Working Behind an HTTP Proxy

In some environments, the connection to external services, from the servers or VMs, requires an HTTP(S) proxy.

=== Configure an HTTP Proxy During Installation

You can configure the HTTP(S) proxy during the xref:../installation-setup/methods/iso-install.adoc[ISO installation] as shown in picture below:

image::install/iso-proxy.png[iso-proxy]

=== Configure an HTTP Proxy

You can configure the HTTP(S) proxy using the UI.

. Go to the settings page of the UI.
. Find the `http-proxy` setting, click *⋮ > Edit setting*
. Enter the value(s) for `http-proxy`, `https-proxy` and `no-proxy`.

image::proxy-setting.png[proxy-setting]

[NOTE]
====
SUSE® Virtualization appends necessary addresses to user configured `no-proxy` to ensure the internal traffic works.
i.e., `localhost,127.0.0.1,0.0.0.0,10.0.0.0/8,longhorn-system,cattle-system,cattle-system.svc,harvester-system,.svc,.cluster.local`. `harvester-system` was added into the list since v1.1.2.

When the nodes in the cluster do not use a proxy to communicate with each other, the CIDR needs to be added to `http-proxy.noProxy` after the first node is installed successfully. Please refer to xref:../troubleshooting/cluster.adoc#_fail_to_deploy_a_multi_node_cluster_due_to_incorrect_http_proxy_setting[fail to deploy a multi-node cluster].
====

== Guest Cluster Images

All necessary images to install and run SUSE® Virtualization are conveniently packaged into the ISO, eliminating the need to pre-load images on bare-metal nodes. A SUSE® Virtualization cluster manages them independently and effectively behind the scenes.

However, it's essential to understand a guest K8s cluster (e.g., RKE2 cluster) created by the xref:../integrations/rancher/node-driver/node-driver.adoc[Harvester node driver] is a distinct entity from a SUSE® Virtualization cluster. A guest cluster operates within VMs and requires pulling images either from the internet or a https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/authentication-permissions-and-global-configuration/global-default-private-registry#configure-a-private-registry-with-credentials-when-creating-a-cluster[private registry].

If the *Cloud Provider* option is configured to SUSE® Virtualization in a guest K8s cluster, it deploys the Harvester cloud provider and Container Storage Interface (CSI) driver.

image::cluster-registry.png[cluster-registry]

As a result, we recommend monitoring each https://github.com/rancher/rke2/releases[RKE2 release] in your air gapped environment and pulling the required images into your private registry. Please refer to the https://www.suse.com/suse-harvester/support-matrix/all-supported-versions/harvester-v1-1-2/[Support Matrix page] for the best Harvester cloud provider and CSI driver capability support.
