= Creating an RKE1 Kubernetes Cluster
:revdate: 2025-06-09
:page-revdate: {revdate}

[WARNING]
====
Rancher Kubernetes Engine (RKE) will reach the end of its life on **July 31, 2025**. {harvester-product-name} **v1.6.0** and later versions will not support RKE. Switching to {rke2-product-name}, which provides a more secure and efficient environment, is recommended.

In-place upgrades are not an option, so you must create new RKE2 clusters and migrate the workloads from your existing RKE clusters (known as replatforming). For more information, see https://www.suse.com/support/kb/doc/?id=000021513[RKE End of Life].
====

You can now provision RKE1 Kubernetes clusters on top of the {harvester-product-name} cluster in {rancher-product-name} using the built-in Harvester Node Driver.

RKE1 and RKE2 have several slight behavioral differences. For more information, see https://documentation.suse.com/cloudnative/rancher-manager/v2.10/en/cluster-deployment/rke1-vs-rke2.html[differences between RKE1 and RKE2].

image::rancher/rke1-node-driver.png[rke1-cluster]

[NOTE]
====
* VLAN network is required for Harvester Node Driver.
* Provisioning RKE1 Kubernetes clusters involves configuring the IP address of the underlying virtual machines. You can do this using a DHCP server on the VLAN network that the virtual machines are attached to. If such a server does not exist on the network, you can use the xref:../../../add-ons/vm-dhcp-controller.adoc[Managed DHCP] feature to configure the IP address.
* Harvester Node Driver only supports cloud images.
* For port requirements of guest clusters deployed within {harvester-product-name}, please refer to the xref:../../../installation-setup/requirements.adoc#_port_requirements_for_k3s_or_rkerke2_clusters[port requirements for guest clusters].
====

When you create a Kubernetes cluster hosted by the {harvester-product-name} infrastructure, https://rancher.com/docs/rancher/v2.6/en/cluster-provisioning/rke-clusters/node-pools/#node-templates[node templates] are used to provision the cluster nodes. These templates use Docker Machine configuration options to define an operating system image and settings/parameters for the node.

Node templates can use `cloud credentials` to access the credentials information required to provision nodes in the infrastructure providers. The same `cloud credentials` can be used by multiple node templates. By using `cloud credentials`, you do not have to re-enter access keys for the same cloud provider. `Cloud credentials` are stored as Kubernetes secrets.

You can create `cloud credentials` in two contexts:

* https://rancher.com/docs/rancher/v2.6/en/cluster-provisioning/rke-clusters/node-pools/#node-templates[During the creation of a node template] for a cluster.
* In the User Settings page

All `cloud credentials` are bound to your user profile and cannot be shared with other users.

== Create your cloud credentials

. Click *â˜° > Cluster Management*.
. Click *Cloud Credentials*.
. Click *Create*.
. Click *Harvester*.
. Enter your cloud credential name.
. Select "Imported Harvester Cluster".
. Click *Create*.

image::rancher/create-cloud-credentials.png[create-harvester-cloud-credentials]

== Create node templates

You can use the Harvester Node Driver to create node templates and eventually node pools for your Kubernetes cluster.

. Configure the  *Cloud Credentials*.
. Configure *Instance Options*:
 ** Configure the CPU, memory, and disk
 ** Select an OS image that is compatible with the `cloud-init` config.
 ** Select a network that the node driver is able to connect to; currently, only `VLAN` is supported.
 ** Enter the SSH User; the username will be used to ssh to nodes. For example, a default user of the Ubuntu cloud image will be `ubuntu`.
. (Optional) Configure *Advanced Options* if you want to customise the cloud-init config of the VMs:
. Enter a *RANCHER TEMPLATE* name.

image::rancher/node-template.png[]

See https://rancher.com/docs/rancher/v2.6/en/cluster-provisioning/rke-clusters/node-pools/[nodes hosted by an infrastructure provider] for more information.

=== Add node affinity

The Harvester Node Driver now supports scheduling a group of machines to particular nodes through the node affinity rules, which can provide high availability and better resource utilization.

Node affinity can be added to the node template during the cluster creation, click `Add Node Template` or edit your existing node template via `RKE1 Configuration > Node Templates`:

. Check the `Advanced Options` tab and click `Add Node Selector`
image:rancher/affinity-add-node-selector.png[affinity-add-node-selector]
. Set priority to `Required` if you wish the scheduler to schedule the machines only when the rules are met.
. Click `Add Rule` to specify the node affinity rules, e.g., for the xref:./node-driver.adoc#_topology_spread_constraints[topology spread constraints] use case, you can add the `region` and `zone` labels as follows:
+
[,yaml]
----
key: topology.kubernetes.io/region
operator: in list
values: us-east-1
---
key: topology.kubernetes.io/zone
operator: in list
values: us-east-1a
----
+
image::rancher/affinity-add-rules.png[affinity-add-rules]

. Click `Create` to save the node template. After the cluster is installed, you can check whether its machine nodes are scheduled accordingly to the affinity rules.

== Create an RKE1 Kubernetes cluster

Users can create an RKE1 Kubernetes cluster from the *Cluster Management* page via the Harvester RKE1 node driver.

. Select *Clusters* menu.
. Click *Create* button.
. Toggle Switch to *RKE1*.
. Select Harvester Node Driver.
. Enter *Cluster Name* (required).
. Enter *Name Prefix* (required).
. Enter *Template* (required).
. Select *etcd* and *Control Plane* (required).
. On the *Cluster Options* configure `Cloud Provider` to `Harvester` if you want to use the Harvester xref:../../../integrations/rancher/cloud-provider.adoc[Cloud Provider] and xref:../../../integrations/rancher/csi-driver.adoc[CSI Driver].
image:rancher/enable-harvester-cloud-provider.png[]
. Click *Create*.

image::rancher/create-rke-harvester-cluster.png[create-rke-harvester-cluster]

== Using Harvester RKE1 node driver in air-gapped environments

RKE1 provisioning relies on the `qemu-guest-agent` to get the IP of the virtual machine, and `docker` to set up the RKE cluster. However, It may not be feasible to install `qemu-guest-agent` and `docker` in an air gapped environment.

You can address the installation constraints with the following options:

* Option 1. Use a VM image preconfigured with both `qemu-guest-agent` and `docker`.
* Option 2. Configure the `cloud-init` user data to enable the VMs to install `qemu-guest-agent` and `docker` via an HTTP(S) proxy.

Example user data in {harvester-product-name} node template:

----
#cloud-config
apt:
  http_proxy: http://192.168.0.1:3128
  https_proxy: http://192.168.0.1:3128
write_files:
- path: /etc/environment
  content: |
    HTTP_PROXY="http://192.168.0.1:3128"
    HTTPS_PROXY="http://192.168.0.1:3128"
  append: true
----